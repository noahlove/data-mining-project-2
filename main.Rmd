---
title: "Main-Project"
author: "Noah Love and Ido Li On"
date: "3/4/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r packages, message=FALSE, warning=FALSE, include=FALSE}

library(tidyverse)
library(tidyjson)
library(jsonlite)
```

# Project 2

## Introduction

The data provided to us for this report is a scraped job postings from [indeed.com](https://www.indeed.com/ "https://www.indeed.com/"). They were scraped from September 2020 to March 2021, in four distinct scrapes.

## The data

So the data is presented in a json file. It is a list of 16 (or 20 for 2021) lists, each representing a unique job category: i.e. ux designer, recruiter or marketing. Within each of the 16 lists, are 2 lists: the first is a list of 4, describing position, location, job time (full or part time), and start time. The second list contains job descriptions associated with that job category.

```{r echo=FALSE}
indeed_2020_raw <- fromJSON("Indeed_data/indeed_job_descs_2020_09_20.json")

indeed_2021 <- fromJSON("Indeed_data/indeed_job_descs_2021_01_25.json")
```

### Clean up the data

Our first major choice was to combine all four data sets (different dates) into one large csv. None of our questions necessarily related to the time aspect of the data so we chose to just unify them. Here is an example of the list of categories, and associated characteristics.

```{r echo=FALSE}
full_df <- as_tibble(read.csv("Indeed_data/merged.csv"))

job_positions <- full_df %>% 
  group_by(job_title) %>% 
  summarise(n = n())

job_positions

```

First, there are only 25 categories here. Definitely not a comprehensive view of the job market, so if you are really set about going into a field that is not listed, this loop project explained below would not be a good fit. However, for most people majoring in statistics or computer science, this might provide a nice survey of various jobs. 

Another question that would be reasonable to ask is what is the distribution of job postings per category?

```{r}
ggplot(data = job_positions, aes(x = job_title, y = n)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  ggtitle("Distribution of the jobs by category for 2020") +
  coord_flip() +
  theme_light()

```

Hopefully you don't want to be a data journalist because the data is not as comprehensive than the rest. But otherwise, it seems to be very equal across the categories. Otherwise, for the categories mentioned, it seems that the data is representative and could be very useful in a job hunt if you have interests in the related field. 


## Tokenize the data

We wrangled all of these into a csv format for easier working. The data frame gives job location, salary minimum and maximum (rare), separate columns for different types of job positions (full time, part time, contract or internship) as well as job title (category), job_id (distinct id number from Indeed) and the job description from the company.

```{r message=FALSE, warning=FALSE}
glimpse(full_df)
```

Here is an (shortened) example of how each job postings appears in JSON:

> "2ccc2596d13c54d4": "Job to be done\nWe\u2019re the best way to get better.\n\nAbout Buoy Health:\nBuoy builds a digital health tool that helps people \u2013 from the moment they get sick \u2013 start their health care on the right foot. Started by a team of doctors and computer scientists working at the Harvard Innovation Laboratory in Boston MA, Buoy was developed in direct response to the downward spiral we\u2019ve all faced when we attempt to self-diagnose our symptoms online...."

### Data Quality Issue

Some companies appear to have gotten lazy in their copy and pasting between websites and have smashed some words together. Because it is a rare enough occurrence, it will hopefully not have a large effect on the data.



## Data processing

Our initial goal was to convert the data into a cosine similarity matrix. For more complex data like this, this type of data interpretation was convenient because we didn't have to find a more clever way of normalizing the data.

```{r, cache = TRUE}
cosine_matrix <- read.csv("Indeed_data/cos_dissm_mat.csv.gz")
```
